<p>To further promote the practical utility and real-world applicability of Disentangled Representation Learning, we are organizing this competition as part of the DRL for Real ICCV 2025 Workshop. The primary goal is to promote the development and evaluation of DRL methods on realistic datasets, thereby accelerating the transition of disentangled models from theoretical research to practical applications.</p>

<h3>Competition Tracks</h3>

<p>The competition is divided into two main tracks:</p>

<h4>1. Single-Factor Track</h4>

<p>This track focuses on disentangled representation learning for single-factor variations in images. The dataset includes over 10,000 images covering multiple scenes, dozens of objects, and hundreds of factors of variation.</p>

<ul>
  <li><strong>Dataset:</strong> High-quality images with controlled single-factor variations</li>
  <li><strong>Requirement:</strong> Participants must use disentangled models in this track</li>
  <li><strong>Evaluation:</strong>
    <ul>
      <li><em>Image Generation Quality (50%):</em> Measured using FID (Fr√©chet Inception Distance)</li>
      <li><em>Disentanglement Quality (50%):</em> Evaluated using Bi-directional DCI, which extends the traditional DCI metric by also measuring how perturbations in real images affect the corresponding latent variables in the encoder</li>
    </ul>
  </li>
</ul>

<h4>2. Multi-Factor Track</h4>

<p>This track is further divided into two sub-tracks, each with two leaderboards:</p>

<h5>2.1 General Image Dataset</h5>

<ul>
  <li><strong>Main Leaderboard:</strong> Open to all methods (not restricted to disentangled approaches)</li>
  <li><strong>Disentanglement Leaderboard:</strong> Only for disentangled methods</li>
  <li><strong>Evaluation for Main Leaderboard:</strong> Uses LLM evaluation approach:
    <ul>
      <li>LLM evaluation of attribute strength in generated images</li>
      <li>Comparison between text-specified attribute changes and LLM-detected attribute changes, with scores closer to 1 indicating better performance (minimal unintended attribute changes)</li>
    </ul>
  </li>
  <li><strong>Evaluation for Disentanglement Leaderboard:</strong> Same metrics as the Single-Factor Track (FID and Bi-directional DCI)</li>
</ul>

<h5>2.2 Autonomous Driving Dataset</h5>

<ul>
  <li><strong>Dataset:</strong> Multi-camera setup with five cameras (four surrounding the vehicle and one overhead view)</li>
  <li><strong>Task:</strong> Given images from one camera viewpoint, generate images for other viewpoints and time points</li>
  <li><strong>Main Leaderboard:</strong> Open to all methods, evaluated using SSIM to measure similarity between generated images and ground truth</li>
  <li><strong>Disentanglement Leaderboard:</strong> Only for disentangled methods, using the same metrics as the Single-Factor Track</li>
</ul>


<h3>Datasets</h3>

<p>Participants will have access to several datasets specifically curated for this competition:</p>

<ul>
  <li><strong>Training Datasets:</strong> Real-world data with annotated factors of variation</li>
  <li><strong>Validation Datasets:</strong> For preliminary evaluation during the development phase</li>
  <li><strong>Hidden Test Datasets:</strong> Unseen data with more challenging scenarios for final evaluation</li>
</ul>

<p>These datasets span multiple domains including images and texts, providing a comprehensive testbed for disentangled representation learning methods.</p>

<p>By training and evaluating models on real-world data, our aim is to foster meaningful advancements in the DRL community and facilitate its integration into practical controllable generation scenarios.</p>
