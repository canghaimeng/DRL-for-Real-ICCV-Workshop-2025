<h2>Submission Guidelines for DRL for Real Competition</h2>

<p>This competition focuses on developing and evaluating disentangled representation learning (DRL) methods on realistic datasets. The competition is divided into two main tracks: Single-Factor and Multi-Factor. Participants are expected to submit their models and results following these guidelines:</p>

<h3>Track-Specific Submission Requirements</h3>

<h4>1. Single-Factor Track</h4>
<ol>
  <li><strong>Model Submission</strong>: Submit your disentangled model along with the code used for training and evaluation. The model must be capable of learning disentangled representations from the provided single-factor variation dataset.</li>
  <li><strong>Documentation</strong>: Include a detailed description of your approach, highlighting how your method achieves disentanglement for single-factor variations.</li>
  <li><strong>Results</strong>: Provide quantitative results on FID and Bi-directional DCI metrics.</li>
  <li><strong>Visualization</strong>: Include visualizations that demonstrate the disentangled nature of your learned representations and the quality of generated images.</li>
</ol>

<h4>2. Multi-Factor Track - General Image Dataset</h4>
<ol>
  <li><strong>Model Submission</strong>: Submit your model along with the code used for training and evaluation.</li>
  <li><strong>Documentation</strong>: Include a detailed description of your approach, specifying whether you're targeting the Main Leaderboard, the Disentanglement Leaderboard, or both.</li>
  <li><strong>Results</strong>: 
    <ul>
      <li>For Main Leaderboard: Provide examples of text-to-image generation with controlled attribute manipulation</li>
      <li>For Disentanglement Leaderboard: Provide quantitative results on FID and Bi-directional DCI metrics</li>
    </ul>
  </li>
  <li><strong>Visualization</strong>: Include visualizations that demonstrate your model's ability to generate images with specific attribute changes.</li>
</ol>

<h4>3. Multi-Factor Track - Autonomous Driving Dataset</h4>
<ol>
  <li><strong>Model Submission</strong>: Submit your model along with the code used for training and evaluation.</li>
  <li><strong>Documentation</strong>: Include a detailed description of your approach, specifying whether you're targeting the Main Leaderboard, the Disentanglement Leaderboard, or both.</li>
  <li><strong>Results</strong>: 
    <ul>
      <li>For Main Leaderboard: Provide examples of cross-view image generation and SSIM scores</li>
      <li>For Disentanglement Leaderboard: Provide quantitative results on FID and Bi-directional DCI metrics</li>
    </ul>
  </li>
  <li><strong>Visualization</strong>: Include visualizations that demonstrate your model's ability to generate images from different camera viewpoints and time points.</li>
</ol>

<h3>Evaluation Criteria</h3>

<p>Submissions will be evaluated based on track-specific criteria:</p>

<ul>
  <li><strong>Single-Factor Track:</strong>
    <ul>
      <li><em>Image Generation Quality (50%):</em> Measured using FID</li>
      <li><em>Disentanglement Quality (50%):</em> Evaluated using Bi-directional DCI</li>
    </ul>
  </li>
  <li><strong>Multi-Factor Track - General Image Dataset:</strong>
    <ul>
      <li><em>Main Leaderboard:</em> LLM+VQA evaluation approach</li>
      <li><em>Disentanglement Leaderboard:</em> FID (50%) and Bi-directional DCI (50%)</li>
    </ul>
  </li>
  <li><strong>Multi-Factor Track - Autonomous Driving Dataset:</strong>
    <ul>
      <li><em>Main Leaderboard:</em> SSIM between generated images and ground truth</li>
      <li><em>Disentanglement Leaderboard:</em> FID (50%) and Bi-directional DCI (50%)</li>
    </ul>
  </li>
</ul>

<h3>Submission Format</h3>

<p>Please submit your files in one of the following formats: .zip, .tar.gz, or through a GitHub repository link. Ensure that your submission includes all necessary code, models, and documentation as specified above. Clearly indicate which track(s) and leaderboard(s) you are submitting to.</p>